import { OpenAIStream, OpenAIStreamPayload } from "../../utils/OpenAIStream";

if (process.env.NEXT_PUBLIC_USE_USER_KEY !== "true") {
  if (!process.env.OPENAI_API_KEY) {
    throw new Error("Missing env var from OpenAI");
  }
}

export const config = {
  runtime: "edge",
};

const handler = async (req: Request): Promise<Response> => {
  var { prompt, api_key } = (await req.json()) as {
    prompt?: string;
    api_key?: string
  };
  //todo make this variable into messages
  var p = "ä½œä¸ºä¸€åå°çº¢ä¹¦æ–‡æ¡ˆåˆ›ä½œç§è‰è¾¾äººï¼Œä½ éœ€è¦å…·å¤‡é«˜æ°´å‡†çš„æ–‡æ¡ˆå†™ä½œæŠ€å·§ã€å¯¹å¹´è½»ç”¨æˆ·å¿ƒç†çš„æ•é”æ´å¯ŸåŠ›ï¼Œä»¥åŠå¼ºçƒˆçš„å¸‚åœºæ•æ„Ÿåº¦ã€‚ä¸»è¦èŒè´£åŒ…æ‹¬ï¼šæ ¹æ®å°çº¢ä¹¦å¹³å°çš„ç‰¹ç‚¹æ’°å†™æå…·â€œç§è‰â€æ•ˆæœçš„å†…å®¹ï¼Œè¿ç”¨çˆ†æ¬¾å…³é”®è¯ã€çƒ­é—¨è¯é¢˜ã€ä»¥åŠå°çº¢ä¹¦ç‹¬ç‰¹çš„ç¬¦å·ï¼Œå¦‚â€œâœ¨â€â€œâ¤ï¸â€â€œğŸ“Œâ€ç­‰ï¼Œè®©ç”¨æˆ·ä¸€çœ¼å°±è¢«å¸å¼•ã€‚ä½ è¿˜åº”ç†Ÿç»ƒä½¿ç”¨é€‚åˆå°çº¢ä¹¦çš„æ–‡æ¡ˆç»“æ„ï¼Œå¦‚åˆ†æ®µè®²è§£ã€ç¬¦å·åˆ—è¡¨å’Œé—®ç­”äº’åŠ¨é£æ ¼ï¼Œä»¥ä¾¿å†…å®¹æ›´æ˜“é˜…è¯»ï¼Œæå‡ç”¨æˆ·å‚ä¸åº¦å’Œäº’åŠ¨ç‡ã€‚ä¿æŒäº²åˆ‡è‡ªç„¶çš„è¯­æ°”ï¼Œåˆ†äº«çœŸå®çš„ä½“éªŒå’Œå®ç”¨çš„å»ºè®®ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨è½»æ¾æ„‰å¿«çš„é˜…è¯»ä¸­äº†è§£äº§å“æˆ–å†…å®¹ã€‚"
  prompt = p + prompt
  if (!prompt) {
    return new Response("No prompt in the request", { status: 400 });
  }

  // if (!process.env.OPENAI_MODEL) {
  //   throw new Error("Missing env var from OpenAI")
  // }

  const payload: OpenAIStreamPayload = {
    model: "moonshot-v1-8k",
    messages: [{ role: "user", content: prompt }],
    temperature: 0.7,
    top_p: 1,
    frequency_penalty: 0,
    presence_penalty: 0,
    max_tokens: 1000,
    stream: true,
    n: 1,
    api_key,
  }

  const stream = await OpenAIStream(payload);
  return new Response(stream);
};

export default handler;
